{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook is useful when a batch stopped in the middle and you know the ID or when you want to see how are all your batches\n",
    "\n",
    "Note: It may make sense to get the latest batch and then use this"
   ],
   "id": "fcdcf5091ed86ae5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:07.134387Z",
     "start_time": "2025-01-29T20:09:06.969240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from wikipedia_markdown.utils.yaml import load_yaml\n",
    "from wikipedia_markdown.utils.database import update_llm_cleaned_row\n",
    "\n",
    "load_dotenv()\n",
    "openai_token = getenv(\"OPENAI_TOKEN\")\n",
    "\n",
    "client = OpenAI()"
   ],
   "id": "6a3cdd4ba1b7f43f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check batches",
   "id": "91bbc7aaaceb8090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:10.204053Z",
     "start_time": "2025-01-29T20:09:09.551438Z"
    }
   },
   "cell_type": "code",
   "source": "batches = client.batches.list(limit=50)",
   "id": "aa039dbc07cc707f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Check status single batch"
   ],
   "id": "d9d84baf9d7007f4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:12.636889Z",
     "start_time": "2025-01-29T20:09:12.421744Z"
    }
   },
   "source": [
    "batch_id = \"batch_679a7779e2988190b956489961393a5e\"\n",
    "\n",
    "batch = client.batches.retrieve(batch_id)\n",
    "print(batch)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_679a7779e2988190b956489961393a5e', completion_window='24h', created_at=1738176378, endpoint='/v1/chat/completions', input_file_id='file-QKsAqMeY5MCzZHTTX3U75S', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1738262778, failed_at=None, finalizing_at=None, in_progress_at=1738176380, metadata={'description': 'Batch 2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=2067))\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download single batch",
   "id": "f6f172a416b36ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:18.423473Z",
     "start_time": "2025-01-29T20:09:17.871537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the base path\n",
    "base_path = Path(\"../\")\n",
    "\n",
    "# Load the YAML configuration\n",
    "config_path = base_path / \"config.yaml\"\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "# Set the directory to save batch results\n",
    "results_path = base_path / config[\"openai_batch_job_results_path\"]\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Retrieve the batch job details\n",
    "batch = client.batches.retrieve(batch_id)\n",
    "if not batch.output_file_id:\n",
    "    print(f\"No output file found for batch {batch_id}. Skipping.\")\n",
    "else:\n",
    "    # Download the output file content\n",
    "    file_response = client.files.content(batch.output_file_id)\n",
    "\n",
    "    # Construct the path to save the result\n",
    "    result_file_name = f\"batch_result_{batch_id}.jsonl\"\n",
    "    result_file_path = results_path / result_file_name\n",
    "\n",
    "    # Save the content to the file\n",
    "    with open(result_file_path, \"wb\") as f:\n",
    "        f.write(file_response.content)\n",
    "\n",
    "    print(f\"Batch job result saved to {result_file_path}\")"
   ],
   "id": "644fb47d7e6d138e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No output file found for batch batch_679a7779e2988190b956489961393a5e. Skipping.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Insert in DB results of single batch",
   "id": "f78978d6d050fbaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:00.669381Z",
     "start_time": "2025-01-29T20:08:05.687172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_jsonl_and_update_db(\n",
    "    jsonl_file_path: Path, db_path: Path, debug: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a `.jsonl` file and update the database.\n",
    "\n",
    "    Args:\n",
    "        jsonl_file_path (Path): Path to the `.jsonl` file containing batch job results.\n",
    "        db_path (Path): Path to the SQLite database file.\n",
    "        debug (bool): If True, print debug messages (default: False).\n",
    "    \"\"\"\n",
    "    with open(jsonl_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            # Parse each line as a JSON object\n",
    "            row = json.loads(line)\n",
    "\n",
    "            # Extract the required data\n",
    "            custom_id = int(row[\"custom_id\"])  # The ID of the row in the database\n",
    "            response_body = row[\"response\"][\"body\"]\n",
    "            assistant_content = response_body[\"choices\"][0][\"message\"][\n",
    "                \"content\"\n",
    "            ]  # Assistant's response\n",
    "            completion_tokens = response_body[\"usage\"][\n",
    "                \"completion_tokens\"\n",
    "            ]  # Token count\n",
    "            model = response_body[\"model\"]  # Model used for processing\n",
    "\n",
    "            # Update the database row\n",
    "            update_llm_cleaned_row(\n",
    "                db_path=db_path,\n",
    "                id=custom_id,\n",
    "                model=model,\n",
    "                llm_cleaned_text=assistant_content,\n",
    "                llm_cleaned_text_tokens=completion_tokens,\n",
    "                debug=debug,\n",
    "            )\n"
   ],
   "id": "8f59d6de0c78adae",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:09:00.672111Z",
     "start_time": "2025-01-29T20:08:05.705065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Construct the full path to the database file\n",
    "data_folder = base_path / config[\"data_folder\"]\n",
    "db_file = config[\"db_file\"]\n",
    "db_path = data_folder / db_file\n",
    "\n",
    "result_file_name = f\"batch_result_{batch_id}.jsonl\"\n",
    "result_file_path = results_path / result_file_name\n",
    "\n",
    "# Process the `.jsonl` file and update the database\n",
    "process_jsonl_and_update_db(\n",
    "    jsonl_file_path=result_file_path,\n",
    "    db_path=db_path,\n",
    "    debug=True,  # Set to True to print debug messages\n",
    ")"
   ],
   "id": "a265652d04a27f87",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../openai_batch_job_results/batch_result_batch_679a7779e2988190b956489961393a5e.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m result_file_path \u001B[38;5;241m=\u001B[39m results_path \u001B[38;5;241m/\u001B[39m result_file_name\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Process the `.jsonl` file and update the database\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mprocess_jsonl_and_update_db\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjsonl_file_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresult_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdb_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdb_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Set to True to print debug messages\u001B[39;49;00m\n\u001B[1;32m     14\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[15], line 12\u001B[0m, in \u001B[0;36mprocess_jsonl_and_update_db\u001B[0;34m(jsonl_file_path, db_path, debug)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mprocess_jsonl_and_update_db\u001B[39m(\n\u001B[1;32m      2\u001B[0m     jsonl_file_path: Path, db_path: Path, debug: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m      3\u001B[0m ):\n\u001B[1;32m      4\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m    Process a `.jsonl` file and update the database.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m        debug (bool): If True, print debug messages (default: False).\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mjsonl_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m file:\n\u001B[1;32m     14\u001B[0m             \u001B[38;5;66;03m# Parse each line as a JSON object\u001B[39;00m\n\u001B[1;32m     15\u001B[0m             row \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(line)\n",
      "File \u001B[0;32m~/Documents/GitHub/wikipedia-markdown/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../../openai_batch_job_results/batch_result_batch_679a7779e2988190b956489961393a5e.jsonl'"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
